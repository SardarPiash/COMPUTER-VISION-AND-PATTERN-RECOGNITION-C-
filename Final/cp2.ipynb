{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First, let's import the necessary libraries and load the dataset:"
      ],
      "metadata": {
        "id": "jdbI05XUk05w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cNQZhSikNNZ",
        "outputId": "87475a38-7dc5-42b4-87e9-1f279fd2543a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go on to defining the starting point for our transfer learning framework. A VGG16 model that has already been trained on the ImageNet dataset will be used."
      ],
      "metadata": {
        "id": "WhZsrM0hlO0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.VGG16(\n",
        "    weights=\"imagenet\",  \n",
        "    input_shape=(32, 32, 3),\n",
        "    include_top=False,\n",
        ")  \n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka9g5dgclumm",
        "outputId": "6df66b9a-8939-4e2e-da1a-76d217adbab4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now add some additional layers on top of the base model, and train the entire model end-to-end:"
      ],
      "metadata": {
        "id": "IXrwzp9Rl-kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "predictions = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history1 = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "for layer in base_model.layers[:15]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history2 = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHB7RM4MmCrj",
        "outputId": "b2ef9686-3a51-4cfb-ef6d-f90eab9e6b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 742s 474ms/step - loss: 1.4882 - accuracy: 0.4755 - val_loss: 1.2750 - val_accuracy: 0.5507\n",
            "Epoch 2/10\n",
            " 873/1563 [===============>..............] - ETA: 4:32 - loss: 1.3183 - accuracy: 0.5374"
          ]
        }
      ]
    }
  ]
}